<!-- Publications page -->

<html>
<head>
    <title>Publications - Vardhan Dongre</title>
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link rel="stylesheet" type="text/css" href="css/publications.css">
</head>

<body>
    <div class="content">
        <nav class="navigation">
            <a href="index.html">← Back to Home</a>
        </nav>
        
        <h1>Publications</h1>
        <h2>Research Papers & Publications</h2>
        
        <div class="publications-container">
            <div class="publication">
                <div class="publication-header">
                    <h3 class="publication-title">A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions</h3>
                    <span class="publication-year">2025</span>
                </div>
                <div class="publication-authors">
                    Emre Can Acikgoz, Cheng Qian, Hongru Wang, <strong>Vardhan Dongre</strong>, Xiusi Chen, Heng Ji, Dilek Hakkani-Tür, Gokhan Tur
                </div>
                <div class="publication-venue">
                    arXiv preprint
                </div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2504.16939" class="publication-link" target="_blank">Paper</a>
                </div>
                <div class="publication-abstract">
                    Recent advances in Large Language Models (LLMs) have propelled conversational AI from traditional dialogue systems into sophisticated agents capable of autonomous actions, contextual awareness, and multi-turn interactions with users. This survey paper presents a desideratum for next-generation Conversational Agents - what has been achieved, what challenges persist, and what must be done for more scalable systems that approach human-level intelligence. We systematically analyze LLM-driven Conversational Agents by organizing their capabilities into three primary dimensions: (i) Reasoning - logical, systematic thinking inspired by human intelligence for decision making, (ii) Monitor - encompassing self-awareness and user interaction monitoring, and (iii) Control - focusing on tool utilization and policy following.
                </div>
            </div>

            <div class="publication">
                <div class="publication-header">
                    <h3 class="publication-title">ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents</h3>
                    <span class="publication-year">2024</span>
                </div>
                <div class="publication-authors">
                    <strong>Vardhan Dongre</strong>, Xiaocheng Yang, Emre Can Acikgoz, Suvodip Dey, Gokhan Tur, Dilek Hakkani-Tür
                </div>
                <div class="publication-venue">
                    International Workshop on Spoken Dialogue Systems Technology (Oral)
                </div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2411.00927" class="publication-link" target="_blank">Paper</a>
                </div>
                <div class="publication-abstract">
                    Large language model (LLM)-based agents are increasingly employed to interact with external environments to solve user-provided tasks. In this work, we introduce ReSpAct, an LLM-based agent designed to seamlessly integrate reasoning, decision-making, and dynamic dialogue for task-solving. Expanding on reasoning-first approaches like ReAct, ReSpAct employs active, free-flowing dialogues to interpret instructions, clarify goals, provide status updates, resolve subtask failures, and refine plans based on user inputs without any explicit dialogue schema. ReSpAct demonstrates improved performance across diverse environments including task-oriented dialogue systems (MultiWOZ) and decision-making tasks (ALFWorld, WebShop).
                </div>
            </div>
        </div>

        <div class="publications-note">
            <p>
                For a complete list of publications, please visit my 
                <a href="https://scholar.google.com/citations?user=sSt2OvIAAAAJ&hl=en&authuser=1">Google Scholar profile</a>.
            </p>
        </div>
    </div>
</body>
</html> 